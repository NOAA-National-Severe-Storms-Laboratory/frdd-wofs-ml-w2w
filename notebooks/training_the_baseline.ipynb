{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6131ebb",
   "metadata": {},
   "source": [
    "# Training the Baseline Model \n",
    "\n",
    "### Primary Goal: Train an accurate baseline model for the individual severe weather hazards. \n",
    "\n",
    "In this notebook, I'll provide a brief tutorial on how to train and evaluate a baseline model. It is not only helpful, but crucial to develop a simplier, baseline model against which to evaluate the skill of the machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ece0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Plotting code imports \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# We add the github package to our system path so we can import python scripts for that repo. \n",
    "import sys\n",
    "sys.path.append('/home/monte.flora/python_packages/2to6_hr_severe_wx/')\n",
    "from main.io import load_bl_data\n",
    "from main.evaluator import baseline_cv_scorer\n",
    "from sklearn.isotonic import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aea1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables (You'll need to change based on where you store your data)\n",
    "base_path = '/work/mflora/ML_2TO6HR/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c6c98",
   "metadata": {},
   "source": [
    "### Neighborhood Maximum Ensemble Probability (NMEP)\n",
    "\n",
    "For the baseline system, we use a single variable approach in which we compute the ensemble probability and extract the maximum value within a track. To compute the ensemble probability ($EP$), we threshold a variable $f$ on some threshold $t$ for each ensemble member and compute the average number of members exceeding that threshold:\n",
    "\\begin{equation}\n",
    "\t        EP = \\frac{1}{N}\\sum_{i=1}^{N} f_i > t\n",
    "\\end{equation}\n",
    "\n",
    "The following variables and their threshold are as follows: \n",
    "   * Tornado $\\rightarrow$ Updraft Helicity (`uh_2ot5_instant`)\n",
    "   * Severe Hail $\\rightarrow$ HAILCAST (`hailcast`)\n",
    "   * Severe Wind $\\rightarrow$ 80-m wind speed (`ws_80`)\n",
    "   \n",
    "   \n",
    "For the NMEP, we apply a local maximum value filter to each ensemble member prior to computing the $EP$. By finding the maximum value within some neighborhood, we are accounting for the spatial uncertainty. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> <b>Task:</b> Per hazard and target variable, determine the most skillful threshold and scale   </div>\n",
    "\n",
    "To improve the probabilistic guidance provided by the baseline system, we used [isotonic regression](https://scikit-learn.org/stable/modules/isotonic.html) to calibrate the probabilities. We used the cross-validation approach from [Platt 1999](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639) to train the calibration model where the prediction and target values on each validation set are concatenated together and then isotonic regression is fit on that combined dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872123a5",
   "metadata": {},
   "source": [
    "## Step 1. Evaluate the NMEP at different thresholds and scales. \n",
    "\n",
    "As a first example, I've provided some code that evaluates the NMEP using cross-validation on the training dataset. Your goal will be to determine the best threshold and scale per hazard. You'll want to create a figure similar to Fig. 1 in [Loken et al. 2020](https://journals.ametsoc.org/view/journals/wefo/35/4/wafD190258.xml), which will be a great addition to your paper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80faad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this command to learn about the input args for the load_bl_data function.\n",
    "#help(load_bl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9d60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, dates = load_bl_data(mode='train', \n",
    "                            target_col = 'hail_severe__36km', \n",
    "                            base_path = base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a513ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to see the full list of features. \n",
    "#list(df.columns)\n",
    "\n",
    "# Here is the breakdown for the naming convention \n",
    "# [hailcast|ws_80|uh_2to5_instant]__nmep__>[thresholds]_[9|27|45]km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02afb656",
   "metadata": {},
   "source": [
    "Here is an example of how to use the `baseline_cv_scorer` function. You'll want to write a for loop to iterate over the different thresholds and scales. You'll want to keep the mean value for each set of `cv_scores`. Since you have two degrees of freedom (threshold and scale), the final figure will look like a heatmap. For an easy plotting example, look at the [seaborn heat map](https://seaborn.pydata.org/generated/seaborn.heatmap.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8219f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['hailcast__nmep_>1_0_45km']\n",
    "cv_scores = baseline_cv_scorer(X, y, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64500c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08014548477546724,\n",
       " 0.09350032993617319,\n",
       " 0.0993842394765001,\n",
       " 0.08826115904731913,\n",
       " 0.07402634167696376]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46658",
   "metadata": {},
   "source": [
    "## Step 2. Training the final, calibrated model \n",
    "\n",
    "Once you are confident about the best threshold and scale, you can train the final baseline model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05cfb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(X,y,dates, save_name):\n",
    "    \"\"\"Train a baseline model and then save it.\"\"\"\n",
    "    clf = IsotonicRegression(out_of_bounds='clip', y_min=0, y_max=1)\n",
    "    clf.fit(X, y)\n",
    "    joblib.dump(clf, save_name, compress=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff9d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a save path for the baseline model. \n",
    "save_name = 'hail_baseline_model.joblib'\n",
    "train_baseline(X,y,dates, save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
