{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cffd680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from WoF_post.wofs.post.utils import (\n",
    "    save_dataset,\n",
    "    load_multiple_nc_files,\n",
    ")\n",
    "from WoF_post.wofs.verification.lsrs.get_storm_reports import StormReports\n",
    "from WoF_post.wofs.plotting.util import decompose_file_path\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from scipy.ndimage import uniform_filter, maximum_filter \n",
    "from collections import ChainMap\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from os.path import join\n",
    "import itertools\n",
    "import pyresample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e160fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_config = { 'ENS_VARS':  ['uh_2to5_instant',\n",
    "                            'uh_0to2_instant',\n",
    "                            'wz_0to2_instant',\n",
    "                            'comp_dz',\n",
    "                            'ws_80',\n",
    "                            'hailcast',\n",
    "                            'w_up',\n",
    "                            'okubo_weiss',\n",
    "                    ],\n",
    "             \n",
    "              'ENV_VARS' : ['mid_level_lapse_rate', \n",
    "                            'low_level_lapse_rate', \n",
    "                           ],\n",
    "             \n",
    "              'SVR_VARS': ['shear_u_0to1', \n",
    "                        'shear_v_0to1', \n",
    "                        'shear_u_0to6', \n",
    "                        'shear_v_0to6',\n",
    "                        'shear_u_3to6', \n",
    "                        'shear_v_3to6',\n",
    "                        'srh_0to3',\n",
    "                        'cape_ml', \n",
    "                        'cin_ml', \n",
    "                        'stp',\n",
    "                        'scp',\n",
    "                       ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab173f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#\n",
    "# DATA PIPELINE SCRIPT FOR THE 2-6 HR WOFS-ML-SEVERE PRODUCTS\n",
    "#\n",
    "# Git Author: monte-flora (monte.flora@noaa.gov) \n",
    "####################################################################################\n",
    "\n",
    "from WoF_post.wofs.post.utils import (\n",
    "    save_dataset,\n",
    "    load_multiple_nc_files,\n",
    ")\n",
    "from WoF_post.wofs.verification.lsrs.get_storm_reports import StormReports\n",
    "from WoF_post.wofs.plotting.util import decompose_file_path\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from scipy.ndimage import uniform_filter, maximum_filter \n",
    "from collections import ChainMap\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from os.path import join\n",
    "import itertools\n",
    "import pyresample \n",
    "\n",
    "\n",
    "# These are the list of variables that are pulled from the WoFS\n",
    "# summary files. The list is informed by previous work (Flora et al. 2021, MWR) \n",
    "\n",
    "ml_config = { 'ENS_VARS':  ['uh_2to5_instant',\n",
    "                            'uh_0to2_instant',\n",
    "                            'wz_0to2_instant',\n",
    "                            'comp_dz',\n",
    "                            'ws_80',\n",
    "                            'hailcast',\n",
    "                            'w_up',\n",
    "                            'okubo_weiss',\n",
    "                    ],\n",
    "             \n",
    "              'ENV_VARS' : ['mid_level_lapse_rate', \n",
    "                            'low_level_lapse_rate', \n",
    "                           ],\n",
    "             \n",
    "              'SVR_VARS': ['shear_u_0to1', \n",
    "                        'shear_v_0to1', \n",
    "                        'shear_u_0to6', \n",
    "                        'shear_v_0to6',\n",
    "                        'shear_u_3to6', \n",
    "                        'shear_v_3to6',\n",
    "                        'srh_0to3',\n",
    "                        'cape_ml', \n",
    "                        'cin_ml', \n",
    "                        'stp',\n",
    "                        'scp',\n",
    "                       ]\n",
    "            }\n",
    "\n",
    "def get_files(path):\n",
    "    \"\"\"Get the ENS, ENV, and SVR file paths for the 2-6 hr forecasts\"\"\"\n",
    "    # Load summary files between time step 24-72. \n",
    "    ens_files = glob(join(path,'wofs_ENS_[2-7]*'))\n",
    "    ens_files.sort()\n",
    "    ens_files = ens_files[4:]\n",
    "    \n",
    "    svr_files = [f.replace('ENS', 'SVR') for f in ens_files]\n",
    "    env_files = [f.replace('ENS', 'ENV') for f in ens_files]\n",
    "    \n",
    "    return ens_files, env_files, svr_files\n",
    "    \n",
    "def load_dataset(path):\n",
    "    \"\"\"Load the 2-6 hr forecasts\"\"\"\n",
    "    ens_files, env_files, svr_files = get_files(path)\n",
    "    \n",
    "    coord_vars = [\"xlat\", \"xlon\", \"hgt\"]\n",
    "    X_strm, coords, _, _  = load_multiple_nc_files(\n",
    "                ens_files, concat_dim=\"time\", coord_vars=coord_vars,  load_vars=ml_config['ENS_VARS'])\n",
    "\n",
    "    X_env, _, _, _  = load_multiple_nc_files(\n",
    "                env_files, concat_dim=\"time\", coord_vars=coord_vars,  load_vars=ml_config['ENV_VARS'])\n",
    "\n",
    "    X_svr, _, _, _ = load_multiple_nc_files(\n",
    "                svr_files, concat_dim=\"time\", coord_vars=coord_vars,  load_vars=ml_config['SVR_VARS'])\n",
    "\n",
    "    X_env = {**X_env, **X_svr}\n",
    "\n",
    "    X_env = {v : X_env[v][1] for v in X_env.keys()}\n",
    "    X_strm = {v : X_strm[v][1] for v in X_strm.keys()}\n",
    "    \n",
    "    ll_grid = (coords['xlat'][1].values, coords['xlon'][1].values)\n",
    "    \n",
    "    return X_env, X_strm, ens_files[0], ll_grid\n",
    "\n",
    "class GridPointExtracter:\n",
    "    \"\"\"Upscale X, compute time-composites, compute ensemble statistics.\n",
    "    \n",
    "    Attributes\n",
    "    -------------------------\n",
    "    \n",
    "    ncfile : path-like \n",
    "        The summary file path for either the ENS, ENV, or SVR file at the beginning of the \n",
    "        4-hr period. Used for determining getting the correct reports for labelling. \n",
    "    \n",
    "    env_vars : list of strs \n",
    "        The environmental variables. These variables are 4-hr time-averaged and \n",
    "        are upscaled using a spatial average filter. \n",
    "    \n",
    "    strm_vars : list of strs\n",
    "        The intra-storm variables. These variables are 4-hr time-maxed and \n",
    "        are upscaled using a spatial maximum filter. \n",
    "    \n",
    "    ll_grid : 2-tuple of 2D arrays \n",
    "        original latitude and longitude grids prior to the resampling. \n",
    "    \n",
    "    upscale_size : int (default = 3)\n",
    "        The initial upscaling radius (in grid points). This initial upscaling \n",
    "        coarsens the grid resolution to improve processing times. \n",
    "        \n",
    "    forecast_sizes : list of ints\n",
    "        The radius of the forecast upscalings (in grid points). Internally, the\n",
    "        radius are converted to the diameters for the \n",
    "        scipy.ndimage.uniform_filter and scipy.ndimage.maximum_filter. \n",
    "        d = 2*r \n",
    "        \n",
    "    target_sizes : list of ints\n",
    "        The radius of the targets upscalings (in grid points). Internally, the\n",
    "        radius are converted to the diameters for the scipy.ndimage.uniform_filter. \n",
    "        d = 2*r \n",
    "        \n",
    "    grid_spacing : int \n",
    "        Grid spacing (in km) of the original grid. \n",
    "    \"\"\"\n",
    "    def __init__(self, ncfile, env_vars, strm_vars, ll_grid, \n",
    "                 forecast_sizes=[1,3,5], \n",
    "                 target_sizes = [1,2,4,6],\n",
    "                 upscale_size=3, \n",
    "                 grid_spacing=3,\n",
    "                 reports_path = '/work/mflora/LSRS/STORM_EVENTS_2017-2022.csv',\n",
    "                 report_type = 'NOAA'\n",
    "                ):\n",
    "        \n",
    "        self._n_ens = 18\n",
    "        self._env_vars = env_vars\n",
    "        self._strm_vars = strm_vars\n",
    "        \n",
    "        self._upscale_size = upscale_size\n",
    "        self._SIZES = np.array(forecast_sizes)*2\n",
    "        self._TARGET_SIZES = np.array(target_sizes)*2\n",
    "        self._ncfile = ncfile\n",
    "        self._DX = grid_spacing * upscale_size  \n",
    "        self._reports_path = reports_path\n",
    "        self._report_type = report_type\n",
    "        \n",
    "        if np.max(np.absolute(ll_grid[0]))>90:\n",
    "            raise ValueError('Latitude values for ll_grid > 90 and are likely longitude values. Switch the input.')\n",
    "        \n",
    "        self._original_grid = ll_grid \n",
    "\n",
    "        self._target_grid = (ll_grid[0][::upscale_size, ::upscale_size], \n",
    "                             ll_grid[1][::upscale_size, ::upscale_size]\n",
    "                            ) \n",
    "\n",
    "        # Baseline variables and their corresponding thresholds. \n",
    "        self._BASELINE_VARS = ['hailcast', 'uh_2to5_instant', 'ws_80']\n",
    "        self._NMEP_THRESHS = {'hailcast' : [0.5, 0.75, 1.0, 1.25, 1.5], \n",
    "                             'uh_2to5_instant' : [50, 75, 100, 125, 150, 175, 200],\n",
    "                             'ws_80' : [30, 40, 50, 60], \n",
    "                            }\n",
    "        \n",
    "    def __call__(self, X_env, X_strm, predict=False):\n",
    "        \n",
    "        # TODO: Pre-processor. Get rid of super high updraft speeds, replace NaNs, etc. \n",
    "         \n",
    "        \n",
    "        # This X has had a 3-grid point gaussian smoother applied to it. \n",
    "        X_env_upscaled = {v  : self.upscaler(X_env[v], \n",
    "                                     func=uniform_filter,\n",
    "                                     size=self._upscale_size) for v in self._env_vars}\n",
    "        \n",
    "        # This X has had a 3-grid point maximum filter applied to it. \n",
    "        X_strm_upscaled = {v : self.upscaler(X_strm[v], \n",
    "                                     func=maximum_filter,\n",
    "                                     size=self._upscale_size) for v in self._strm_vars}\n",
    "        \n",
    "        # For the environment, \n",
    "        # 1. Time-average \n",
    "        # 2. Spatial ensemble statistics at different scales. \n",
    "        X_env_time_comp = self.calc_time_composite(X_env_upscaled, \n",
    "                                                    func=np.nanmean, name='time_avg', keys=self._env_vars)\n",
    "        \n",
    "        \n",
    "        X_env_stats = self.calc_spatial_ensemble_stats(X_env_time_comp, environ=True)\n",
    "        \n",
    "        # For the storm, \n",
    "        # 1. Time-maximum \n",
    "        # 2. Spatial ensemble statistics at different scales. \n",
    "        # 3. Amplitude Statistics\n",
    "        X_strm_time_comp = self.calc_time_composite(X_strm_upscaled, \n",
    "                                                    func=np.nanmax, name='time_max', keys=self._strm_vars)\n",
    "        \n",
    "        X_strm_stats = self.calc_spatial_ensemble_stats(X_strm_time_comp, environ=False)\n",
    "        \n",
    "        X_all = {**X_strm_stats, **X_env_stats}\n",
    "        \n",
    "        if predict:\n",
    "            data = X_all\n",
    "        else:\n",
    "            # IF not predicting, then get the target values. \n",
    "            y = self.get_targets()\n",
    "            data = {**X_all, **y}\n",
    "\n",
    "        \n",
    "        # Stack the data and convert to dataframe. \n",
    "        data = {v : (['NY', 'NX'], data[v]) for v in data.keys()}\n",
    "        ds = xr.Dataset(data)\n",
    "        df = ds.stack(z=('NY', 'NX')).to_dataframe()\n",
    "        \n",
    "        ds.close()\n",
    "        \n",
    "        # Convert target variable to binary values. \n",
    "        # In the to_grid code, it gives each report a unique label\n",
    "        # which is used for the object matching. \n",
    "        ys = [f for f in df.columns if 'severe' in f]\n",
    "        \n",
    "        new_df = df.copy()\n",
    "        for y_var in ys:\n",
    "            new_df[y_var] = np.where(df[y_var]>0, 1, 0)\n",
    "        \n",
    "        # Add date and init time\n",
    "        comps = self._ncfile.split('/')\n",
    "        date, init_time = comps[-3], comps[-2]\n",
    "        new_df[\"Run Date\"] = [date]*len(df)\n",
    "        new_df[\"Init Time\"] = [init_time]*len(df)\n",
    "        \n",
    "        return new_df\n",
    "    \n",
    "    def get_nmep(self, X, size):\n",
    "        \"\"\"Compute the Neighborhood Maximum Ensemble Probability baseline\"\"\"\n",
    "        X_nmep = {}\n",
    "        for v in self._BASELINE_VARS:\n",
    "            for t in self._NMEP_THRESHS[v]:\n",
    "                data = X[f'{v}__time_max__{self._DX*size}km']\n",
    "                data_bin = np.where(data>t,1,0)\n",
    "                ens_prob = np.nanmean(data_bin, axis=0)\n",
    "                X_nmep[f\"{v}__nmep_>{str(t).replace('.','_')}_{self._DX*size}km\"] = ens_prob\n",
    "                \n",
    "        return X_nmep \n",
    "\n",
    "    def get_targets(self):\n",
    "        \"\"\"Convert storm reports to a grid and apply different upscaling\"\"\"\n",
    "        comps = decompose_file_path(self._ncfile)\n",
    "        start_time = comps['VALID_DATE']+comps['VALID_TIME']\n",
    "        report = StormReports(\n",
    "            self._reports_path, \n",
    "            self._report_type, \n",
    "            start_time, \n",
    "            forecast_length=240,\n",
    "            err_window=15,               \n",
    "            )\n",
    "\n",
    "        ds = xr.load_dataset(self._ncfile, decode_times=False)\n",
    "        report_ds = report.to_grid(dataset=ds, size=self._upscale_size)\n",
    "        \n",
    "        keys = list(report_ds.data_vars)\n",
    "        \n",
    "        y = {v : report_ds[v].values[::self._upscale_size, ::self._upscale_size] \n",
    "             for v in keys}\n",
    "        \n",
    "        # Upscale the targets. \n",
    "        y_final = [] \n",
    "        for size in self._TARGET_SIZES:\n",
    "            y_nghbrd = {f'{v}__{self._DX*size}km' : self.neighborhooder(y[v], \n",
    "                                                                      func=maximum_filter,\n",
    "                                                                     size=size, is_2d=True) for v in keys}\n",
    "            y_final.append(y_nghbrd)\n",
    "            \n",
    "        y_final = dict(ChainMap(*y_final)) \n",
    "        \n",
    "        return y_final\n",
    "    \n",
    "    \n",
    "    def resample(self, variable):\n",
    "        '''\n",
    "        Resamples (i.e., re-projects, re-grid) the original grid to the target grid \n",
    "        using a nearest neighborhood approach\n",
    "        \n",
    "        Parameters\n",
    "        --------------------\n",
    "            target_grid: 2-tuple of 2D arrays \n",
    "                target latitude and longitude grids for the resampling. \n",
    "                \n",
    "            original_grid : 2-tuple of 2D arrays \n",
    "                original latitude and longitude grids prior to the resampling. \n",
    "                \n",
    "            variable : 2D array to be resampled\n",
    "                The grid to be resampled. \n",
    "                \n",
    "        Return\n",
    "        -----------------------\n",
    "            variable_nearest, 2D array of variable resampled to the target grid\n",
    "        '''\n",
    "        # Create a pyresample object holding the original grid\n",
    "        orig_def = pyresample.geometry.SwathDefinition(lons=self._original_grid[1], lats=self._original_grid[0])\n",
    "\n",
    "        # Create another pyresample object for the target grid\n",
    "        targ_def = pyresample.geometry.SwathDefinition(lons=self._target_grid[1], lats=self._target_grid[0])\n",
    "\n",
    "        variable_nearest = pyresample.kd_tree.resample_nearest(orig_def, variable, \\\n",
    "                    targ_def, radius_of_influence=50000, fill_value=None)\n",
    "\n",
    "        return variable_nearest\n",
    "    \n",
    "    def neighborhooder(self, X, func, size, is_2d=False):\n",
    "        \"\"\"Apply neighborhood function to X. For any grid points with NaN values, \n",
    "           replace it with a generic, full-domain spatial average value.\"\"\"\n",
    "        new_X = X.copy()\n",
    "        fill_value = np.nanmean(X)\n",
    "        if is_2d:\n",
    "            for n in range(self._n_ens):\n",
    "                X_ = np.nan_to_num(X[:,:], nan=fill_value)\n",
    "                new_X[:,:] = func(X_, size)\n",
    "        else:\n",
    "            for n in range(self._n_ens):\n",
    "                X_ = np.nan_to_num(X[n,:,:], nan=fill_value)\n",
    "                new_X[n,:,:] = func(X_, size)\n",
    "    \n",
    "        return new_X \n",
    "    \n",
    "    def upscaler(self, X, func, size, remove_nans=False):\n",
    "        \"\"\"Applies a spatial filter per ensemble member and timestep and then \n",
    "        subsamples the grid to reduce the number of grid points.\"\"\"\n",
    "        new_X = np.zeros((X.shape[0], X.shape[1], \n",
    "                          self._target_grid[0].shape[0], self._target_grid[0].shape[1] ))\n",
    "        \n",
    "        fill_value = np.nanmean(X)\n",
    "        for t,n in itertools.product(range(new_X.shape[0]), range(self._n_ens)):\n",
    "            X_ = np.nan_to_num(X[t,n,:,:], nan=fill_value)\n",
    "            new_X[t,n,:,:] = self.resample(func(X_, size))\n",
    "            \n",
    "        return new_X\n",
    "    \n",
    "    def calc_time_composite(self, X, func, name, keys):\n",
    "        \"\"\"Compute the time-maximum or time-average\"\"\"\n",
    "        X_time_comp = {f'{v}__{name}' : func(X[v], axis=0) for v in keys }\n",
    "        return X_time_comp\n",
    "        \n",
    "    def calc_spatial_ensemble_stats(self, X, environ=True):\n",
    "        \"\"\"Compute the spatial ensemble mean and standard deviation if environ = True,\n",
    "        else compute the ensemble 90th. Ensemble statistics are computed in multiple different \n",
    "        neighborhood sizes\"\"\"\n",
    "        \n",
    "        keys = X.keys()\n",
    "        \n",
    "        X_final = []\n",
    "        \n",
    "        for size in self._SIZES:\n",
    "            if environ:\n",
    "                X_nghbrd = {f'{v}__{self._DX*size}km' : self.neighborhooder(X[v], \n",
    "                                                                      func=uniform_filter,\n",
    "                                                                     size=size, \n",
    "                                                                           ) for v in keys}\n",
    "                \n",
    "                X_ens_mean = {f'{v}__ens_mean' : np.nanmean(X_nghbrd[v], axis=0) for v in X_nghbrd.keys()}\n",
    "                X_ens_std = {f'{v}__ens_std' : np.nanstd(X_nghbrd[v], axis=0, ddof=1) for v in X_nghbrd.keys()}   \n",
    "                X_ens_stats = {**X_ens_mean, **X_ens_std}\n",
    "            \n",
    "            else:\n",
    "                X_nghbrd = {f'{v}__{self._DX*size}km' : self.neighborhooder(X[v], \n",
    "                                                                      func=maximum_filter,\n",
    "                                                                     size=size,      \n",
    "                                                                           ) for v in keys}\n",
    "                \n",
    "                X_ens_90th = {f'{v}__ens_90th' : np.nanpercentile(X_nghbrd[v],\n",
    "                                                                90, axis=0) for v in X_nghbrd.keys()} \n",
    "                \n",
    "                # Compute the baseline stuff. \n",
    "                X_baseline = self.get_nmep(X_nghbrd, size)\n",
    "\n",
    "                X_ens_stats = {**X_baseline, **X_ens_90th}\n",
    "            \n",
    "            X_final.append(X_ens_stats)\n",
    "            \n",
    "        X_final = dict(ChainMap(*X_final))    \n",
    "            \n",
    "        return X_final \n",
    "    \n",
    "def subsampler(y, pos_percent=1.0, neg_percent=0.25):\n",
    "\n",
    "    pos_inds = np.where(y>0)[0]\n",
    "    neg_inds = np.where(y==0)[0]\n",
    "    \n",
    "    if len(pos_inds) > 0:\n",
    "        pos_inds_sub = np.random.choice(pos_inds, size=int(pos_percent*(len(pos_inds))), replace=False)\n",
    "    else:\n",
    "        pos_inds_sub = [] \n",
    "    \n",
    "    neg_inds_sub = np.random.choice(neg_inds, size=int(neg_percent*(len(neg_inds))), replace=False)\n",
    "\n",
    "    inds = np.concatenate([pos_inds_sub, neg_inds_sub])\n",
    "    \n",
    "    return inds     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ba1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_env, X_strm, ncfile, ll_grid = load_dataset('/work/mflora/SummaryFiles/20210504/2300')\n",
    "#ll_grid = (ll_grid['xlat'][1].values, ll_grid['xlon'][1].values)\n",
    "extracter = GridPointExtracter(ncfile, env_vars=X_env.keys(), strm_vars=X_strm.keys(), ll_grid=ll_grid)\n",
    "df = extracter(X_env, X_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42466cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hailcast__nmep_&gt;0_5_90km</th>\n",
       "      <th>hailcast__nmep_&gt;0_75_90km</th>\n",
       "      <th>hailcast__nmep_&gt;1_0_90km</th>\n",
       "      <th>hailcast__nmep_&gt;1_25_90km</th>\n",
       "      <th>hailcast__nmep_&gt;1_5_90km</th>\n",
       "      <th>uh_2to5_instant__nmep_&gt;50_90km</th>\n",
       "      <th>uh_2to5_instant__nmep_&gt;75_90km</th>\n",
       "      <th>uh_2to5_instant__nmep_&gt;100_90km</th>\n",
       "      <th>uh_2to5_instant__nmep_&gt;125_90km</th>\n",
       "      <th>uh_2to5_instant__nmep_&gt;150_90km</th>\n",
       "      <th>...</th>\n",
       "      <th>hail_sig_severe__36km</th>\n",
       "      <th>wind_sig_severe__36km</th>\n",
       "      <th>tornado_severe__18km</th>\n",
       "      <th>hail_severe__18km</th>\n",
       "      <th>wind_severe__18km</th>\n",
       "      <th>tornado_sig_severe__18km</th>\n",
       "      <th>hail_sig_severe__18km</th>\n",
       "      <th>wind_sig_severe__18km</th>\n",
       "      <th>Run Date</th>\n",
       "      <th>Init Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <th>NX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99</th>\n",
       "      <th>95</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210504</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hailcast__nmep_>0_5_90km  hailcast__nmep_>0_75_90km  \\\n",
       "NY NX                                                        \n",
       "0  0                   0.000000                   0.000000   \n",
       "   1                   0.000000                   0.000000   \n",
       "   2                   0.000000                   0.000000   \n",
       "   3                   0.000000                   0.000000   \n",
       "   4                   0.000000                   0.000000   \n",
       "...                         ...                        ...   \n",
       "99 95                  0.055556                   0.055556   \n",
       "   96                  0.055556                   0.000000   \n",
       "   97                  0.000000                   0.000000   \n",
       "   98                  0.000000                   0.000000   \n",
       "   99                  0.000000                   0.000000   \n",
       "\n",
       "       hailcast__nmep_>1_0_90km  hailcast__nmep_>1_25_90km  \\\n",
       "NY NX                                                        \n",
       "0  0                        0.0                        0.0   \n",
       "   1                        0.0                        0.0   \n",
       "   2                        0.0                        0.0   \n",
       "   3                        0.0                        0.0   \n",
       "   4                        0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "99 95                       0.0                        0.0   \n",
       "   96                       0.0                        0.0   \n",
       "   97                       0.0                        0.0   \n",
       "   98                       0.0                        0.0   \n",
       "   99                       0.0                        0.0   \n",
       "\n",
       "       hailcast__nmep_>1_5_90km  uh_2to5_instant__nmep_>50_90km  \\\n",
       "NY NX                                                             \n",
       "0  0                        0.0                        0.000000   \n",
       "   1                        0.0                        0.000000   \n",
       "   2                        0.0                        0.000000   \n",
       "   3                        0.0                        0.000000   \n",
       "   4                        0.0                        0.000000   \n",
       "...                         ...                             ...   \n",
       "99 95                       0.0                        0.222222   \n",
       "   96                       0.0                        0.166667   \n",
       "   97                       0.0                        0.166667   \n",
       "   98                       0.0                        0.166667   \n",
       "   99                       0.0                        0.166667   \n",
       "\n",
       "       uh_2to5_instant__nmep_>75_90km  uh_2to5_instant__nmep_>100_90km  \\\n",
       "NY NX                                                                    \n",
       "0  0                         0.000000                         0.000000   \n",
       "   1                         0.000000                         0.000000   \n",
       "   2                         0.000000                         0.000000   \n",
       "   3                         0.000000                         0.000000   \n",
       "   4                         0.000000                         0.000000   \n",
       "...                               ...                              ...   \n",
       "99 95                        0.111111                         0.055556   \n",
       "   96                        0.055556                         0.000000   \n",
       "   97                        0.055556                         0.000000   \n",
       "   98                        0.055556                         0.000000   \n",
       "   99                        0.000000                         0.000000   \n",
       "\n",
       "       uh_2to5_instant__nmep_>125_90km  uh_2to5_instant__nmep_>150_90km  ...  \\\n",
       "NY NX                                                                    ...   \n",
       "0  0                          0.000000                              0.0  ...   \n",
       "   1                          0.000000                              0.0  ...   \n",
       "   2                          0.000000                              0.0  ...   \n",
       "   3                          0.000000                              0.0  ...   \n",
       "   4                          0.000000                              0.0  ...   \n",
       "...                                ...                              ...  ...   \n",
       "99 95                         0.055556                              0.0  ...   \n",
       "   96                         0.000000                              0.0  ...   \n",
       "   97                         0.000000                              0.0  ...   \n",
       "   98                         0.000000                              0.0  ...   \n",
       "   99                         0.000000                              0.0  ...   \n",
       "\n",
       "       hail_sig_severe__36km  wind_sig_severe__36km  tornado_severe__18km  \\\n",
       "NY NX                                                                       \n",
       "0  0                       0                      0                     0   \n",
       "   1                       0                      0                     0   \n",
       "   2                       0                      0                     0   \n",
       "   3                       0                      0                     0   \n",
       "   4                       0                      0                     0   \n",
       "...                      ...                    ...                   ...   \n",
       "99 95                      0                      0                     0   \n",
       "   96                      0                      0                     0   \n",
       "   97                      0                      0                     0   \n",
       "   98                      0                      0                     0   \n",
       "   99                      0                      0                     0   \n",
       "\n",
       "       hail_severe__18km  wind_severe__18km  tornado_sig_severe__18km  \\\n",
       "NY NX                                                                   \n",
       "0  0                   0                  0                         0   \n",
       "   1                   0                  0                         0   \n",
       "   2                   0                  0                         0   \n",
       "   3                   0                  0                         0   \n",
       "   4                   0                  0                         0   \n",
       "...                  ...                ...                       ...   \n",
       "99 95                  0                  0                         0   \n",
       "   96                  0                  0                         0   \n",
       "   97                  0                  0                         0   \n",
       "   98                  0                  0                         0   \n",
       "   99                  0                  0                         0   \n",
       "\n",
       "       hail_sig_severe__18km  wind_sig_severe__18km  Run Date  Init Time  \n",
       "NY NX                                                                     \n",
       "0  0                       0                      0  20210504       2300  \n",
       "   1                       0                      0  20210504       2300  \n",
       "   2                       0                      0  20210504       2300  \n",
       "   3                       0                      0  20210504       2300  \n",
       "   4                       0                      0  20210504       2300  \n",
       "...                      ...                    ...       ...        ...  \n",
       "99 95                      0                      0  20210504       2300  \n",
       "   96                      0                      0  20210504       2300  \n",
       "   97                      0                      0  20210504       2300  \n",
       "   98                      0                      0  20210504       2300  \n",
       "   99                      0                      0  20210504       2300  \n",
       "\n",
       "[10000 rows x 176 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0018f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hailcast__nmep_>0_5_90km',\n",
       " 'hailcast__nmep_>0_75_90km',\n",
       " 'hailcast__nmep_>1_0_90km',\n",
       " 'hailcast__nmep_>1_25_90km',\n",
       " 'hailcast__nmep_>1_5_90km',\n",
       " 'uh_2to5_instant__nmep_>50_90km',\n",
       " 'uh_2to5_instant__nmep_>75_90km',\n",
       " 'uh_2to5_instant__nmep_>100_90km',\n",
       " 'uh_2to5_instant__nmep_>125_90km',\n",
       " 'uh_2to5_instant__nmep_>150_90km',\n",
       " 'uh_2to5_instant__nmep_>175_90km',\n",
       " 'uh_2to5_instant__nmep_>200_90km',\n",
       " 'ws_80__nmep_>30_90km',\n",
       " 'ws_80__nmep_>40_90km',\n",
       " 'ws_80__nmep_>50_90km',\n",
       " 'ws_80__nmep_>60_90km',\n",
       " 'uh_2to5_instant__time_max__90km__ens_90th',\n",
       " 'uh_0to2_instant__time_max__90km__ens_90th',\n",
       " 'wz_0to2_instant__time_max__90km__ens_90th',\n",
       " 'comp_dz__time_max__90km__ens_90th',\n",
       " 'ws_80__time_max__90km__ens_90th',\n",
       " 'hailcast__time_max__90km__ens_90th',\n",
       " 'w_up__time_max__90km__ens_90th',\n",
       " 'okubo_weiss__time_max__90km__ens_90th',\n",
       " 'hailcast__nmep_>0_5_54km',\n",
       " 'hailcast__nmep_>0_75_54km',\n",
       " 'hailcast__nmep_>1_0_54km',\n",
       " 'hailcast__nmep_>1_25_54km',\n",
       " 'hailcast__nmep_>1_5_54km',\n",
       " 'uh_2to5_instant__nmep_>50_54km',\n",
       " 'uh_2to5_instant__nmep_>75_54km',\n",
       " 'uh_2to5_instant__nmep_>100_54km',\n",
       " 'uh_2to5_instant__nmep_>125_54km',\n",
       " 'uh_2to5_instant__nmep_>150_54km',\n",
       " 'uh_2to5_instant__nmep_>175_54km',\n",
       " 'uh_2to5_instant__nmep_>200_54km',\n",
       " 'ws_80__nmep_>30_54km',\n",
       " 'ws_80__nmep_>40_54km',\n",
       " 'ws_80__nmep_>50_54km',\n",
       " 'ws_80__nmep_>60_54km',\n",
       " 'uh_2to5_instant__time_max__54km__ens_90th',\n",
       " 'uh_0to2_instant__time_max__54km__ens_90th',\n",
       " 'wz_0to2_instant__time_max__54km__ens_90th',\n",
       " 'comp_dz__time_max__54km__ens_90th',\n",
       " 'ws_80__time_max__54km__ens_90th',\n",
       " 'hailcast__time_max__54km__ens_90th',\n",
       " 'w_up__time_max__54km__ens_90th',\n",
       " 'okubo_weiss__time_max__54km__ens_90th',\n",
       " 'hailcast__nmep_>0_5_18km',\n",
       " 'hailcast__nmep_>0_75_18km',\n",
       " 'hailcast__nmep_>1_0_18km',\n",
       " 'hailcast__nmep_>1_25_18km',\n",
       " 'hailcast__nmep_>1_5_18km',\n",
       " 'uh_2to5_instant__nmep_>50_18km',\n",
       " 'uh_2to5_instant__nmep_>75_18km',\n",
       " 'uh_2to5_instant__nmep_>100_18km',\n",
       " 'uh_2to5_instant__nmep_>125_18km',\n",
       " 'uh_2to5_instant__nmep_>150_18km',\n",
       " 'uh_2to5_instant__nmep_>175_18km',\n",
       " 'uh_2to5_instant__nmep_>200_18km',\n",
       " 'ws_80__nmep_>30_18km',\n",
       " 'ws_80__nmep_>40_18km',\n",
       " 'ws_80__nmep_>50_18km',\n",
       " 'ws_80__nmep_>60_18km',\n",
       " 'uh_2to5_instant__time_max__18km__ens_90th',\n",
       " 'uh_0to2_instant__time_max__18km__ens_90th',\n",
       " 'wz_0to2_instant__time_max__18km__ens_90th',\n",
       " 'comp_dz__time_max__18km__ens_90th',\n",
       " 'ws_80__time_max__18km__ens_90th',\n",
       " 'hailcast__time_max__18km__ens_90th',\n",
       " 'w_up__time_max__18km__ens_90th',\n",
       " 'okubo_weiss__time_max__18km__ens_90th',\n",
       " 'mid_level_lapse_rate__time_avg__90km__ens_mean',\n",
       " 'low_level_lapse_rate__time_avg__90km__ens_mean',\n",
       " 'shear_u_0to1__time_avg__90km__ens_mean',\n",
       " 'shear_v_0to1__time_avg__90km__ens_mean',\n",
       " 'shear_u_0to6__time_avg__90km__ens_mean',\n",
       " 'shear_v_0to6__time_avg__90km__ens_mean',\n",
       " 'shear_u_3to6__time_avg__90km__ens_mean',\n",
       " 'shear_v_3to6__time_avg__90km__ens_mean',\n",
       " 'srh_0to3__time_avg__90km__ens_mean',\n",
       " 'cape_ml__time_avg__90km__ens_mean',\n",
       " 'cin_ml__time_avg__90km__ens_mean',\n",
       " 'stp__time_avg__90km__ens_mean',\n",
       " 'scp__time_avg__90km__ens_mean',\n",
       " 'mid_level_lapse_rate__time_avg__90km__ens_std',\n",
       " 'low_level_lapse_rate__time_avg__90km__ens_std',\n",
       " 'shear_u_0to1__time_avg__90km__ens_std',\n",
       " 'shear_v_0to1__time_avg__90km__ens_std',\n",
       " 'shear_u_0to6__time_avg__90km__ens_std',\n",
       " 'shear_v_0to6__time_avg__90km__ens_std',\n",
       " 'shear_u_3to6__time_avg__90km__ens_std',\n",
       " 'shear_v_3to6__time_avg__90km__ens_std',\n",
       " 'srh_0to3__time_avg__90km__ens_std',\n",
       " 'cape_ml__time_avg__90km__ens_std',\n",
       " 'cin_ml__time_avg__90km__ens_std',\n",
       " 'stp__time_avg__90km__ens_std',\n",
       " 'scp__time_avg__90km__ens_std',\n",
       " 'mid_level_lapse_rate__time_avg__54km__ens_mean',\n",
       " 'low_level_lapse_rate__time_avg__54km__ens_mean',\n",
       " 'shear_u_0to1__time_avg__54km__ens_mean',\n",
       " 'shear_v_0to1__time_avg__54km__ens_mean',\n",
       " 'shear_u_0to6__time_avg__54km__ens_mean',\n",
       " 'shear_v_0to6__time_avg__54km__ens_mean',\n",
       " 'shear_u_3to6__time_avg__54km__ens_mean',\n",
       " 'shear_v_3to6__time_avg__54km__ens_mean',\n",
       " 'srh_0to3__time_avg__54km__ens_mean',\n",
       " 'cape_ml__time_avg__54km__ens_mean',\n",
       " 'cin_ml__time_avg__54km__ens_mean',\n",
       " 'stp__time_avg__54km__ens_mean',\n",
       " 'scp__time_avg__54km__ens_mean',\n",
       " 'mid_level_lapse_rate__time_avg__54km__ens_std',\n",
       " 'low_level_lapse_rate__time_avg__54km__ens_std',\n",
       " 'shear_u_0to1__time_avg__54km__ens_std',\n",
       " 'shear_v_0to1__time_avg__54km__ens_std',\n",
       " 'shear_u_0to6__time_avg__54km__ens_std',\n",
       " 'shear_v_0to6__time_avg__54km__ens_std',\n",
       " 'shear_u_3to6__time_avg__54km__ens_std',\n",
       " 'shear_v_3to6__time_avg__54km__ens_std',\n",
       " 'srh_0to3__time_avg__54km__ens_std',\n",
       " 'cape_ml__time_avg__54km__ens_std',\n",
       " 'cin_ml__time_avg__54km__ens_std',\n",
       " 'stp__time_avg__54km__ens_std',\n",
       " 'scp__time_avg__54km__ens_std',\n",
       " 'mid_level_lapse_rate__time_avg__18km__ens_mean',\n",
       " 'low_level_lapse_rate__time_avg__18km__ens_mean',\n",
       " 'shear_u_0to1__time_avg__18km__ens_mean',\n",
       " 'shear_v_0to1__time_avg__18km__ens_mean',\n",
       " 'shear_u_0to6__time_avg__18km__ens_mean',\n",
       " 'shear_v_0to6__time_avg__18km__ens_mean',\n",
       " 'shear_u_3to6__time_avg__18km__ens_mean',\n",
       " 'shear_v_3to6__time_avg__18km__ens_mean',\n",
       " 'srh_0to3__time_avg__18km__ens_mean',\n",
       " 'cape_ml__time_avg__18km__ens_mean',\n",
       " 'cin_ml__time_avg__18km__ens_mean',\n",
       " 'stp__time_avg__18km__ens_mean',\n",
       " 'scp__time_avg__18km__ens_mean',\n",
       " 'mid_level_lapse_rate__time_avg__18km__ens_std',\n",
       " 'low_level_lapse_rate__time_avg__18km__ens_std',\n",
       " 'shear_u_0to1__time_avg__18km__ens_std',\n",
       " 'shear_v_0to1__time_avg__18km__ens_std',\n",
       " 'shear_u_0to6__time_avg__18km__ens_std',\n",
       " 'shear_v_0to6__time_avg__18km__ens_std',\n",
       " 'shear_u_3to6__time_avg__18km__ens_std',\n",
       " 'shear_v_3to6__time_avg__18km__ens_std',\n",
       " 'srh_0to3__time_avg__18km__ens_std',\n",
       " 'cape_ml__time_avg__18km__ens_std',\n",
       " 'cin_ml__time_avg__18km__ens_std',\n",
       " 'stp__time_avg__18km__ens_std',\n",
       " 'scp__time_avg__18km__ens_std',\n",
       " 'tornado_severe__108km',\n",
       " 'hail_severe__108km',\n",
       " 'wind_severe__108km',\n",
       " 'tornado_sig_severe__108km',\n",
       " 'hail_sig_severe__108km',\n",
       " 'wind_sig_severe__108km',\n",
       " 'tornado_severe__72km',\n",
       " 'hail_severe__72km',\n",
       " 'wind_severe__72km',\n",
       " 'tornado_sig_severe__72km',\n",
       " 'hail_sig_severe__72km',\n",
       " 'wind_sig_severe__72km',\n",
       " 'tornado_severe__36km',\n",
       " 'hail_severe__36km',\n",
       " 'wind_severe__36km',\n",
       " 'tornado_sig_severe__36km',\n",
       " 'hail_sig_severe__36km',\n",
       " 'wind_sig_severe__36km',\n",
       " 'tornado_severe__18km',\n",
       " 'hail_severe__18km',\n",
       " 'wind_severe__18km',\n",
       " 'tornado_sig_severe__18km',\n",
       " 'hail_sig_severe__18km',\n",
       " 'wind_sig_severe__18km',\n",
       " 'Run Date',\n",
       " 'Init Time']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cf9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
